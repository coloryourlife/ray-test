apiVersion: ray.io/v1
kind: RayService
metadata:
  name: llama-service
spec:
  serviceUnhealthySecondThreshold: 900
  serveConfigV2: |
    applications:
      - name: llama-app
        import_path: llama_service:app
        route_prefix: /
        runtime_env:
          pip: ["transformers", "torch"]
  rayClusterConfig:
    rayVersion: '2.9.0'
    headGroupSpec:
      serviceType: ClusterIP
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          containers:
            - name: ray-head
              image: rayproject/ray:2.9.0
              resources:
                limits:
                  cpu: 2
                  memory: 8Gi
                requests:
                  cpu: 2
                  memory: 8Gi
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
    workerGroupSpecs:
      - groupName: gpu-worker-group
        replicas: 1
        minReplicas: 1
        maxReplicas: 5
        rayStartParams: {}
        template:
          spec:
            nodeSelector:
              accelerator: gpu
            tolerations:
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
            containers:
              - name: ray-worker
                image: rayproject/ray:2.9.0
                resources:
                  limits:
                    cpu: 4
                    memory: 16Gi
                    nvidia.com/gpu: 1
                  requests:
                    cpu: 4
                    memory: 16Gi
                    nvidia.com/gpu: 1
